# 3. 가상화에 관한 대화
복숭아를 먹고 싶은 사람들이 낮잠 자거나 다른 일을 하고 있는 시간에 복숭아를 낚아채서 다른 사람에게 주는 것. 이렇게 해서 여러 개의 가상 복숭아가 있다는 환상, 사람마다 복숭아를 하나씩 가지고 있다는 환상을 만들어 내는것.
os와 관련짓는다면 -> 1개 뿐인 cpu를 각 응용 프로그램이 자신만 사용하는 cpu를 가지게 되었다고 생각하게 만드는 것.

# 4. 프로세스
## 프로세스의 개념
프로세스 : 실행 중인 프로그램

운영체제는 cpu를 가상화해서 무한개에 가까운 cpu가 있다는 환상을 만들어낸다.

시분할 : 컴퓨터 시스템의 자원을 여러 사용자나 작업이 일정한 시간 단위로 공유하는 방식, CPU를 공유하기 때문에 프로세스의 성능은 낮아진다.
시분할 시스템은 주로 라운드 로빈 스케줄링 방식을 사용해서 작업을 처리한다.
(공간분할) : 디스크 분할하는 거
라운드로빈 스케줄링 : 각 작업에 동일한 시간을 할당하고, 첫 번째 작업이 주어진 시간 동안 실행한 후 다음 작업이 시작된다. 모든 작업이 처리된 후 다시 처음 작업으로 돌아가서 반복한다.

메커니즘 : 필요한 기능을 구현하는 방법이나 규칙
정책 : 운영체제 내에서 어떤 결정을 내리기 위한 알고리즘

프로세스를 간단하게 표현하려면 실행되는 동안 접근하거나 영향을 받은 자원의 목록을 작성하면 된다. 왜냐하면 프로세스의 구성 요소를 이해하기 위해서는 하드웨어 상태를 이해해야하기 때문이다.
이때 가장 중요한 하드웨어 구성요소는 메모리이다.
왜냐하면 명령어, 데이터 등이 메모리에 저장되기 때문이다.
레지스터도 중요하다. 
그 중에서 더 중요한 레지스터들
- 프로그램 카운터 (PC) : 컴퓨터 프로세서 내에서 실행될 다음 명령어의 메모리 주소를 저장하는 레지스터, 현재 어떤 명령어 실행하고 있는지 다음에 실행할 명령어가 어디에 있는지를 추적하는 중요한 역할
- 스택 포인터 : 스택 메모리의 최상단 위치를 가리키는 레지스터 스택 메모리에 데이터를 저장하거나 꺼내올 위치를 추적한다. (새로운 스택 프레임의 시작 위치)
- 프레임 포인터 : 함수 호출 시 기준이 되는 스택 프레임의 시작 지점을 가리킨다. 함수의 스택 프레임이 일정하게 유지되도록 도와준다. 스택 프레임의 시작 지점을 가리키는 레지스터

기법 : 어떻게라는 질문에 답을 제공하는 것
정책 : 어느것이라는 질문에 답을 제공

## 프로세스 API

반드시 api로 제공해야하는 몇몇 기본 기능
- 생성 : 새로운 프로세스를 생성할 수 있는 방법을 제공해야한다.
- 제거 : 프로세스를 강제로 제거할 수 있는 인터페이스를 제공해야 한다.
- 대기 : 때로는 어떤 프로세스의 실행 중지를 기다릴 필요가 있다.
- 각종 제어 : 프로세스의 제거, 대기 외에 여러가지 제어 기능이 제공된다. (ex: 일시정지)
- 상태 : 프로세스 상태 정보 얻어내는 인터페이스

## 프로세스 생성 
1. 프로그램 코드와 정적 데이터를 메모리, 프로세스의 주소 공간에 load한다. (코드와 정적 데이터를 메모리에 탑재하기 위해서 운영체제는 디스크의 해당 바이트를 읽어서 메모리 어딘가에 저장해야한다.)
 초기 운영체제들은 프로그램 실행 전 이 과정을 다 했지만, 요즘은 필요할 때 필요한 부분만 메모리 탑재 -> 페이징과 스와핑 동작의 이해 필요
2. 일정량의 메모리가 프로그램의 실행시간 스택 용도로 할당되어야한다. (스택을 초기화해줘야한다.)
3. 힙을 위한 메모리 영역을 할당한다. (힙은 크기가 가변적인 자료 구조를 위해 사용된다.)
4. 입출력 관련 초기화 작업을 수행한다.
5. 프로그램 실행을 위한 준비 끝! -> main()에서부터 프로그램을 실행
6. 운영체제는 CPU를 새로 생성된 프로세스에게 넘기게 되고 프로그램 실행이 시작된다.

페이징 : 프로세스의 메모리를 고정된 크기의 블록으로 나누어 물리 메모리의 비연속적인 공간을 사용할 수 있게 해주는 기술 -> 가상 메모리는 연속적인 주소를 가진다.
스와핑 : 메모리와 디스크 사이에서 프로세스를 통째로 이동시키는 과정, 메모리 부족하면 프로세스를 메모리에서 디스크로 내보내고 필요할 때 다시 메모리로 불러온다.

## 프로세스 상태
- 실행 : 프로세스는 명령어를 실행하고 있다.
- 준비 : 프로세스는 실행할 준비 완료, 운영체제가 다른 프로세스를 실행하는 등의 이유로 대기
- 대기 : 프로세스가 다른 사건 기다리는 동안 프로세스의 수행을 중단시키는 연산

프로세스는 운영체제의 스케줄링 정책에 따라 스케줄이 되면 준비 상태에서 실행 상태로 전이한다.
실행 -> 준비 : 나중에 다시 스케줄 될 수 있는 상태가 되었다.

## 자료 구조
운영체제도 프로그램이기 때문에 다양한 정보를 유지하기 위한 자료 구조를 가지고 있다.
ex) 프로세스 리스트 : 준비 상태의 프로세스 관리, 레지스터 문맥 : 프로세스가 중단되었을 때 해당 프로세스의 레지스터 값들을 저장

실행, 준비, 대기 외의 다른 상태들 : 초기 상태 (프로세스가 생성되는 동안), 최종 상태 ( 프로세스는 종료되었지만 메모리에 남아있음)

# 5. 프로세스 API
unix는 프로세스를 생성하기 위하여 fork()와 exec() 시스템 콜을 사용한다.
wait()는 프로세스가 자신이 생성한 프로세스가 종료되기를 기다리기 원할 때 사용한다.

## fork() 시스템 콜
프로세스 생성에 fork() 시스템 콜이 사용된다.
fork()로 생성된 프로세스는 호출한 프로세스의 복사본이다.
하지만, 자식 프로세스는 완전히 동일한 프로그램을 처음부터 실행하는 것이 아니라 부모 프로세스가 fork()를 호출한 지점부터 자식 프로세스가 실행을 시작한다. 자식 프로세스는 fork()의 반환값으로 0을 받는다. 그리고, 자식 프로세스는 자신의 주소 공간(그래서 자식이 데이터 변경해도 부모에 영향이 없다.), 자신의 레지스터, 자신 PC값(그래서 처음부터 시작되지 않는다)을 갖는다.
fork() 시스템 콜의 반환값이 다르다!!!
부모 : 생성된 자식 프로세스의 PID
자식 : 0

PID : 프로세스 식별자

CPU 스케줄러는 복잡하므로 어떤 프로세스가 먼저 실행된다고 단정하기 어렵다. 이러한 비결정성에 의해서 멀티 스레드 프로그램 실행 시 다양한 문제가 발생한다.
부모와 자식은 동시에 실행된다.

## wait() 시스템 콜
wait() : 부모 프로세스가 자식 프로세스의 종료를 대기해야하는 경우에 사용하는 시스템 콜
자식 프로세스의 종료 시점까지 자신의 실행을 잠시 중지 시킨다. 자식 프로세스가 종료되어야 wait()는 리턴한다.
그러면 순서는 항상 동일함 : 자식 끝나야 부모가 이어서 출력!

## exec() 시스템 콜
자기 자신이 (복사본) 아닌 다른 프로그램을 실행해야할 때 사용한다. -> 현재 실행 중인 프로세스를 새로운 프로그램으로 대체

1. 실행 파일 이름과 인자가 주어지면 해당 실행 파일의 코드와 정적 데이터를 읽어 들여 현재 실행 중인 프로세스의 코드 세그먼트와 정적 데이터 부분을 덮어쓴다. (기존의 코드, 데이터, 스택, 힙 등이 다 새로운 프로그램으로 덮어쓰여진다.) (삭제한 다음에 그 위치에 새로운 애들로 덮어씌워진다.) 
2. 프로세스의 인자를 전달해서 프로그램을 실행한다.
3. 새로운 프로그램의 첫 번째 명령어가 실행되며 호출했던 프로그램은 계속되지 않는다. 따라서 exec() 호출 이후의 코드는 실행되지않는다.
하지만 pid는 변하지 않는다.

exec()가 성공하면 완전히 새로운 프로그램으로 대체되기 때문에 기존 프로그램으로 돌아올 수 없으므로 반환되지 않는다.
따라서 exec() 호출 후에는 오류 처리코드만 작성하는 것이 일반적이다.

## 왜 이런 API를?
왜 fork()와 exec()를 분리했을까?
fork() 한 다음에 exec()를 호출하기 전 환경 설정 등 기능 준비하려고, 분리해서 쉘은 많은 유용한 일을 조금 쉽게할 수 있다.

## 여타 API들
kill() 시스템 콜: 시그널을 보내는데 사용된다. (시그널은 프로세스를 중단시키고, 삭제하는 등의 작업에 사용된다.)

man 페이지를 읽어라

# 6. 제한적 직접 실행
시분할하면 가상화를 구현할 수 있다.
근데 생각할 문제 - 성능 저하, 제어 문제
cpu에 대한 통제를 상실하면 한 프로세스가 영원히 실행을 계속 할 수 있고, 접근해서는 안 되는 정보에 접근할 수도 있다.

## 제한적 직접 실행
직접 실행 : CPU상에서 프로그램을 그냥 직접 실행시키는 것 -> cpu에서 사용자 명령을 사용해서 성능이 극대화된다.
따라서 운영체제가 프로그램을 시작할 때 프로세스 목록에 해당 프로세스 항목을 만들고 메모리를 할당하며 프로그램 코드를 디스크에서 탑재하고 진입점을 찾아 그 지점으로 분기해서 사용자 코드를 실행한다.

근데 그러면 어떻게 프로그램이 나쁜 일 안 하는 거를 보장하냐, 또 시분할 기법을 어떻게 구현하냐 -> 이제 해결할 예정
프로그램 실행에 제한을 두지 않으면 운영체제는 어떠한 것도 제어할 수 없으며 단순한 라이브러리일 뿐이다.

## 문제점 1: 제한된 연산
cpu에서 직접 실행하면 매우 빨라서 좋다 근데, 디스크 입출력 요청이나 cpu 또는 메모리 등에 추가할당 요청 등 특수 연산을 요청하면 어떡하냐?
그래서 사용자 모드가 도입되었다. -> 할 수 있는 일이 제한된다.
제한된 일을 요청하면 프로세서가 예외를 발생시키고 운영체제는 해당 프로세서를 제거한다. 
커널 모드 : 모든 작업을 수행할 수 있다.
그러면 사용자 프로세스가 특권 명령어를 실행해야할 때는 어떡함? -> 시스템 콜 제공 (파일 시스템 접근, 프로세스 생성 및 제거, 다른 프로세스와의 통신 및 메모리 할당 등 포함)
시스템 콜을 실행하기 위해서 프로그램은 trap 특수 명령어를 실행해야한다.
trap 특수 명령어 : 커널 안으로 분기하는 동시에 특권 수준을 커널 모드로 상향 조정한다.
그러면 무슨 일이든 할 수 있음 -> 다 한 다음에 return-from-trap 특수 명령어 호출

trap 명령어 수행할 때는 호출한 프로세스의 필요한 레지스터들을 저장해야한다. -> 다시 사용자 프로세스로 돌아오려고
트랩이 발생하면 하드웨어나 운영체제는 현재 레지스터들의 값을 스택이나 특정 메모리 공간에 저장한다.
그 다음 트랩 핸들러가 필요한 작업 수행하고
작업이 완료되면 저장된 레지스터 값을 복원해서 프로세스가 트랩 발생 지점 이후의 명령어를 정상적으로 실행할 수 있도록 한다.

트랩 명령어는 트랩 번호와 함께 실행된다. 이 트랩 번호는 어떤 서비스나 핸들러를 호출할 지 결정한다. 트랩 번호가 CPU에 의해 트랩 테이블로 전달 되고, 트랩 테이블에서 트랩 번호에 해당하는 핸들러의 주소를 조회한다. 그 후 커널 모드로 전환되고 핸들러가 실행되어서 필요한 운영체제 기능을 수행한다. 작업을 완료했으면 다시 사용자 프로그램으로 제어를 반환한다.

+) 하드웨어는 두 가지 실행 모드를 제공한다.
- 사용자 모드 : 하드웨어 자원에 대한 접근 권한이 일부 제한
- 커널 모드 : 모든 자원에 대한 접근 권한

## 문제점 2 : 프로세스 간 전환
CPU에서 프로세스가 실행 중이면 운영체제는 실행 중이지 않다는 것이고, 그렇다면 프로세스 전환은 이루어질 수 없다.
따라서 운영체제가 CPU를 다시 획득하는 과정이 필요하다.

- 협조 방식 : 프로세스가 순순히 CPU를 포기할 거라고 가정, 그렇다면 어떻게 CPU를 포기할 수 있을까? : yield 시스템 콜
  yield 시스템 콜은 운영체제에게 제어를 넘겨서 운영체제가 다른 프로세스를 실행할 수 있게한다.
  응용 프로그램이 비정상적인 행동하면 운영체제에게 제어가 넘어간다. 그러면 운영체제는 cpu를 획독해서 해당 프로세스를 종료할 수 있다.
- 비협조 방식 : 타이머 인터럽트를 사용하기. 수 밀리초마다 인터럽트를 발생시키도록 프로그램한다. 인터럽트가 발생하면 현재 수행중인 프로세스는 중단되고 미리 구성된 운영체제의 인터럽트 핸들러가 실행된다.
운영체제는 하드웨어에게 타이머 인터럽트가 발생했을때 실행해야 할 코드를 알려주어야 한다

## 문맥의 저장과 복원
운영체제가 제어권을 얻으면 현재 프로세스 실행할건지, 다른 프로세스로 전환할건지 결정해야한다.
다른 프로세스로 전환하기로 결정하면 문맥 교환을 실행한다.
프로세스 전환을 위하여 운영체제는 저수준 어셈블리 코드를 사용하여 현재 실행 중인 프로세스의 범용 레지스터, PC뿐 아니라 현재 커널 스택 포인터를 저장한다.

커널 모드 진입해서 프로세스 바꾸기로 결정하면 switch()루틴을 호출하고 A의 레지스터에 현재 값을 저장하고 B의 구조체에 B 의 레지스터를 복원한다. 그 다음에 A의 커널 스택이 아니라 B의 커널 스택을 사용하도록 스택 포인터를 바꾸어서 문맥 교환을 수행한다.

## 병행성이 걱정
운영체제는 인터럽트 또는 트랩을 처리하는 도중에 다른 인터럽트가 발생할 때 어떤 일이 생기는 지에 대해 신중하게 고려해야한다. 인터럽트 처리 동안은 인터럽트 불능화시키기. 또는 락 사용하기

# 7. 스케줄링 
스케줄링 정책을 생각하기 위한 기본적인 프레임워크를 어떻게 만들어야 하는가? 핵심 가정은 무엇인가? 어떤 평가 기준이 중요한가? 컴퓨터 시스템의 초창기에 사용되었던 기본 접근법은 무엇인가?

## 워크로드에 대한 가정
워크로드 : 일련의 프로세스들이 실행하는 상황

## 스케줄링 평가 항목
스케줄링 평가 항목은 아주 다양하게 존재한다
- 반환 시간 : 작업이 완료된 시각에서 작업이 시스템에 도착한 시간을 뺀 시간 -> 성능 측면의 평가 기준이다. (다른 평가 기준으로는 공정성이 있다)

## FIFO (FCFS)
FIFO : 단순하고 구현하기 쉽다.
단점 : 짧은 시간동안 자원을 사용할 프로세스들이 자원을 오랫동안 사용하는 프로세스의 종료룰 기다리게 된다. (convoy effect)

## SJF
짧은 실행 시간을 가진 작업을 먼저 실행시킨다. (비선점형 스케줄러임)
모든 작업이 동시에 도착한다면 sjf가 최적의 스케줄링 알고리즘이다.

## 최소 잔여시간 우선 (STCF or PSJF)
SJF + 선점 기능
새로운 작업이 시스템에 들어오면 남아있는 작업과 새로운 작업의 잔여 실행시간을 계산하고 그 중 가장 적은 잔여 실행 시간을 가진 작업을 스케줄한다.

## 새로운 평가 기준 : 응답 시간
응답 시간 : 작업이 도착할 때 부터 처음 스케줄 될 때 까지의 시간
STCF랑 비슷한 애들은 응답시간이 짧다고 할 수 없다.

## 라운드 로빈
타임 슬라이스 (스케줄링 퀀텀) : 작업이 실행되는 일정 시간 (타이머 인터럽트 주기의 배수여야 한다.)
타임 슬라이스가 짧을수록 응답 시간 기준으로 RR의 성능은 더 좋아진다. 하지만 너무 짧게하면 문맥 교환 비용이 너무 커져서 성능이 안 좋아진다.
반환 시간이 측정 기준일 경우 RR은 거의 최악의 정책이다.

+) 가능하면 시스템의 활용도를 극대화 하기 위해 연산을 중첩되게 실행한다.

## 입출력 연산의 고려
입출력 요청을 발생시킨 작업은 입출력 완료를 기다리며 대기 상태가 된다.
입출력 완료 시에도 스케줄러는 의사 결정을 해야한다. : 입출력이 완료되면 인터럽트가 발생하고 운영체제가 실행되어 입출력을 요청한 프로세스를 대기 상태에서 준비 상태로 이동시킨다.
중첩을 사용해서 연산을 빠르게 하기
대화형 작업이 입출력을 실행하는 동안 다른 CPU 집중 작업들이 실행되고 CPU의 이용률은 더 높아진다.

멀티레벨 피드백 큐 : 가까운 과거를 이용해서 미래를 예측하는 스케줄러

# 8. 멀티 레벨 피드백 큐 (MLFQ)
1. 짧은 작업을 먼저 실행시켜 반환 시간을 최적화하고자 한다.
2. 응답 시간을 최적화한다.

## MLFQ: 기본 규칙
여러 개의 큐로 구성되며 각각 다른 우선순위가 배정된다. 실행 준비가 된 프로세스는 이 중 하나의 큐에 존재한다.
높은 우선 순위 큐에 존재하는 프로세스를 실행한다. 큐에 둘 이상의 작업이 존재할 때는 RR 사용
MLFQ는 각 작업에 고정된 우선순위를 부여하는 것이 아니라 각 작업의 특성에 따라 동적으로 우선순위를 부여한다. (대화형 프로세스는 우선순위가 높다, CPU 집중적으로 긴 시간 사용하는 애는 우선순위가 낮다.)
이렇게 작업이 진행되는 동안 작업의 정보를 얻고, 이 정보로 미래를 예측한다.

우선순위가 높은 애가 있으면, 높은 애가 실행
우선 순위가 같은 애가 있으면 라운드로빈 방식으로 실행

## 우선 순위의 변경
작업의 우선 순위를 변경하는 것은 작업이 존재할 큐를 결정하는 것과 마찬가지이다. -> 워크로드의 특성을 반영해야한다.
규칙
- 작업이 시스템에 진입하면 가장 높은 우선순위를 가진다
- 주어진 타임 슬라이스를 모두 사용하면 우선순위는 낮아진다. (한 단계 아래로 이동)
- 타임 슬라이스를 소진하기 전에 cpu를 양도하면 우선순위를 유지한다.

스케줄러는 작업이 짧은 작업인지 긴 작업인지 알 수 없기 때문에 일단 짧은 작업이라고 가정해서 높은 우선순위를 부여한다.

## 입출력 작업은?
프로세스가 타임 슬라이스 소진하기 전에 프로세서 양도하면 우선순위 유지한다. -> 알아서 잘 함

## MLFQ의 문제점
1. 기아 상태 발생 가능성 : 너무 많은 대화형 작업이 존해하면 걔네가 CPU 시간 다 씀
2. 똑똑한 사용자는 스케줄러를 자신에게 유리하게 동작하도록 프로그램을 다시 작성할 수 있다. (스케줄러를 속여서 더 많은 시간 할당 받도록 한다 : 타임 슬라이스 끝나기 전에 아무 파일을 대상으로 입출력 요청 내려서 CPU 양도하면?)
3. 프로그램은 시간 흐름에 따라 특성이 변할 수 있다.

## 우선순위의 상향 조정
규칙
- 일정 기간 S가 지나면 시스템의 모든 작업을 최상위 큐로 이동시킨다.

이렇게 하면 기아 상태 없다. 특성이 변할 경우 적합하게 스케줄링 된다.
근데 이 S 적절하게 고르기 넘모 어렵다. (부두 상수)

## 더 나은 시간 측정
똑똑한 사용자 어쩔것인가?
-> 각 단계에서 cpu 총 사용시간을 측정하는 것
: 현재 단계에서 사용한 CPU 사용시간 저장하고, 타임 슬라이스에 해당하는 시간 소진하면 아래로 내리기
규칙 재정의
= 주어진 단계에서 시간 할당량을 소진하면 (CPU 양도랑 상관없이) 우선순위는 낮아진다.

## 다른 쟁점들
큐 몇개? 큐 당 타임 슬라이스 크기는? 우선순위 상향 얼마나 자주?
-> 큐마다 타임 슬라이스 변경할수도 있다. (우선 순위 높은 큐는 짧은 타임 슬라이스, 우선 순위 낮은 큐는 긴 타임 슬라이스)

solaris의 MLFQ 구현 : 테이블을 제공함
명령어 라인 도구 nice : 작업의 우선순위를 높이거나 낮출 수 있다. 작업의 실행 순서를 바꿀 수 있다. 

## 규칙 정리
• 규칙 1 : 우선순위 (A)> 우선순위 (B) 일 경우, A가 실행, B는 실행되지 않는다.
• 규칙 2 : 우선순위 (A) = 우선순위 (B), A와 B는 RR 방식으로 실행된다.
• 규칙 3 : 작업이 시스템에 들어가면 최상위 큐에 배치된다.
• 규칙 4 : 작업이 지정된 단계에서 배정받은 시간을 소진하면 (CPU를 포기한 횟수와 상관없이), 작업의 우선순위는 감소한다 (즉, 한 단계 아래 큐로 이동한다).
• 규칙 5 : 일정 주기 S 가 지난 후, 시스템의 모든 작업을 최상위 큐로 이동시킨다.
